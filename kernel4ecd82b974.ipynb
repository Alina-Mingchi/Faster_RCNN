{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the System\n",
    "Before we actually get into the model building phase, we need to ensure that the right libraries and frameworks have been installed. The below libraries are required to run this project:\n",
    "\n",
    "* pandas\n",
    "* matplotlib\n",
    "* tensorflow\n",
    "* keras – 2.0.3\n",
    "* numpy\n",
    "* opencv-python\n",
    "* sklearn\n",
    "* h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Exploration\n",
    "It’s always a good idea (and frankly, a mandatory step) to first explore the data we have. This helps us not only unearth hidden patterns, but gain a valuable overall insight into what we are working with. The three files I have created out of the entire dataset are:\n",
    "\n",
    "* train_images: Images that we will be using to train the model. We have the classes and the actual bounding boxes for each class in this folder.\n",
    "* test_images: Images in this folder will be used to make predictions using the trained model. This set is missing the classes and the bounding boxes for these classes.\n",
    "* train.csv: Contains the name, class and bounding box coordinates for each image. There can be multiple rows for one image as a single image can have more than one object.\n",
    "Let’s read the .csv file (you can create your own .csv file from the original dataset if you feel like experimenting) and print out the first few rows. We’ll need to first import the below libraries for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib import patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the csv file using read_csv function of pandas\n",
    "train = pd.read_csv(‘BCCD/ImageSets/Main/train.csv’)\n",
    "print(train)\n",
    "train.head()\n",
    "print('1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 6 columns in the train file. Let’s understand what each column represents:\n",
    "\n",
    "1. image_names: contains the name of the image\n",
    "2. cell_type: denotes the type of the cell\n",
    "3. xmin: x-coordinate of the bottom left part of the image\n",
    "4. xmax: x-coordinate of the top right part of the image\n",
    "5. ymin: y-coordinate of the bottom left part of the image\n",
    "6. ymax: y-coordinate of the top right part of the image\n",
    "\n",
    "Let’s now print an image to visualize what we’re working with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading single image using imread function of matplotlib\n",
    "image = plt.imread('images/1.jpg')\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what a blood cell image looks like. Here, the blue part represents the WBCs, and the slightly red parts represent the RBCs. Let’s look at how many images, and the different type of classes, there are in our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique training images\n",
    "train['image_names'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we have 254 training images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of classes\n",
    "train['cell_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have three different classes of cells, i.e., RBC, WBC and Platelets. Finally, let’s look at how an image with detected objects will look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "#add axes to the image\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "\n",
    "# read and plot the image\n",
    "image = plt.imread('images/1.jpg')\n",
    "plt.imshow(image)\n",
    "\n",
    "# iterating over the image for different objects\n",
    "for _,row in train[train.image_names == \"1.jpg\"].iterrows():\n",
    "    xmin = row.xmin\n",
    "    xmax = row.xmax\n",
    "    ymin = row.ymin\n",
    "    ymax = row.ymax\n",
    "    \n",
    "    width = xmax - xmin\n",
    "    height = ymax - ymin\n",
    "    \n",
    "    # assign different color to different classes of objects\n",
    "    if row.cell_type == 'RBC':\n",
    "        edgecolor = 'r'\n",
    "        ax.annotate('RBC', xy=(xmax-40,ymin+20))\n",
    "    elif row.cell_type == 'WBC':\n",
    "        edgecolor = 'b'\n",
    "        ax.annotate('WBC', xy=(xmax-40,ymin+20))\n",
    "    elif row.cell_type == 'Platelets':\n",
    "        edgecolor = 'g'\n",
    "        ax.annotate('Platelets', xy=(xmax-40,ymin+20))\n",
    "        \n",
    "    # add bounding boxes to the image\n",
    "    rect = patches.Rectangle((xmin,ymin), width, height, edgecolor = edgecolor, facecolor = 'none')\n",
    "    \n",
    "    ax.add_patch(rect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what a training example looks like. We have the different classes and their corresponding bounding boxes. Let’s now train our model on these images. We will be using the keras_frcnn library to train our model as well as to get predictions on the test images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing Faster R-CNN\n",
    "\n",
    "For implementing the Faster R-CNN algorithm, we will be following the steps mentioned in this Github repository. So as the first step, make sure you clone this repository. Open a new terminal window and type the following to do this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move the train_images and test_images folder, as well as the train.csv file, to the cloned repository. In order to train the model on a new dataset, the format of the input should be:\n",
    "\n",
    "filepath,x1,y1,x2,y2,class_name\n",
    "\n",
    "where,\n",
    "\n",
    "filepath is the path of the training image\n",
    "* x1 is the xmin coordinate for bounding box\n",
    "* y1 is the ymin coordinate for bounding box\n",
    "* x2 is the xmax coordinate for bounding box\n",
    "* y2 is the ymax coordinate for bounding box\n",
    "* class_name is the name of the class in that bounding box\n",
    "We need to convert the .csv format into a .txt file which will have the same format as described above. Make a new dataframe, fill all the values as per the format into that dataframe, and then save it as a .txt file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "data['format'] = train['image_names']\n",
    "\n",
    "# as the images are in train_images folder, add train_images before the image name\n",
    "for i in range(data.shape[0]):\n",
    "    data['format'][i] = 'train_images/' + data['format'][i]\n",
    "\n",
    "# add xmin, ymin, xmax, ymax and class as per the format required\n",
    "for i in range(data.shape[0]):\n",
    "    data['format'][i] = data['format'][i] + ',' + str(train['xmin'][i]) + ',' + str(train['ymin'][i]) + ',' + str(train['xmax'][i]) + ',' + str(train['ymax'][i]) + ',' + train['cell_type'][i]\n",
    "\n",
    "data.to_csv('annotate.txt', header=None, index=None, sep=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What’s next?\n",
    "\n",
    "Train our model! We will be using the train_frcnn.py file to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd keras-frcnn\n",
    "python train_frcnn.py -o simple -p annotate.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will take a while to train the model due to the size of the data. If possible, you can use a GPU to make the training phase faster. You can also try to reduce the number of epochs as an alternate option. To change the number of epochs, go to the train_frcnn.py file in the cloned repository and change the num_epochs parameter accordingly.\n",
    "\n",
    "Every time the model sees an improvement, the weights of that particular epoch will be saved in the same directory as “model_frcnn.hdf5”. These weights will be used when we make predictions on the test set.\n",
    "\n",
    "It might take a lot of time to train the model and get the weights, depending on the configuration of your machine. I suggest using the weights I’ve got after training the model for around 500 epochs. You can download these weights from here. Ensure you save these weights in the cloned repository.\n",
    "\n",
    "So our model has been trained and the weights are set. It’s prediction time! Keras_frcnn makes the predictions for the new images and saves them in a new folder. We just have to make two changes in the test_frcnn.py file to save the images:\n",
    "\n",
    "1. Remove the comment from the last line of this file:\n",
    "cv2.imwrite(‘./results_imgs/{}.png’.format(idx),img)\n",
    "2. Add comments on the second last and third last line of this file:\n",
    "# cv2.imshow(‘img’, img)\n",
    "# cv2.waitKey(0)\n",
    "Let’s make the predictions for the new images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python test_frcnn.py -p test_images"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
